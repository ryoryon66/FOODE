{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# y' = sin(x) + cos(x) という微分方程式を解く\n",
    "class Diff_Eq:\n",
    "    \n",
    "    bias = 20.0\n",
    "    \n",
    "    x0 = 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def y_prime(x, y):\n",
    "        return torch.sin(x) + torch.cos(x)\n",
    "    \n",
    "    @classmethod\n",
    "    def y0(cls):\n",
    "        return 0.0 + cls.bias\n",
    "    \n",
    "    @classmethod\n",
    "    def y(cls, x):\n",
    "        return torch.sin(x) - torch.cos(x) + 1.0 +  cls.bias\n",
    "\n",
    "# y' = - x y^2 という微分方程式を解く\n",
    "# class Diff_Eq:\n",
    "    \n",
    "#     x0 = 1.\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def y_prime(x, y):\n",
    "#         return - x * y ** 2\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def y0():\n",
    "#         return 1.0 \n",
    "    \n",
    "#     @staticmethod\n",
    "#     def y(x):\n",
    "#         return 2 / (1 + x ** 2) \n",
    "\n",
    "\n",
    "# y' = - 2 x y という微分方程式を解く\n",
    "# class Diff_Eq:\n",
    "    \n",
    "#     x0 = 0.0\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def y_prime(x, y):\n",
    "#         return - 2 * x * y\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def y0():\n",
    "#         return 1.0\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def y(x):\n",
    "#         return torch.exp(- x ** 2) \n",
    "    \n",
    "# 解を描画\n",
    "x = torch.linspace(0, 10, 1000)\n",
    "y = Diff_Eq.y(x)\n",
    "plt.plot(x, y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self,x_from=0, x_to=20,length = 300000):\n",
    "        \n",
    "        self.x_from = x_from\n",
    "        self.x_to = x_to\n",
    "        self.length = length\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = torch.rand(1) * (self.x_to - self.x_from) + self.x_from\n",
    "        \n",
    "        return x\n",
    "    \n",
    "dataset = EqDataset()\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        def build_layers(in_features, out_features):\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(in_features, out_features),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            build_layers(1, 20),\n",
    "            build_layers(20, 20),\n",
    "            build_layers(20, 20),\n",
    "            build_layers(20, 20),\n",
    "            build_layers(20, 20),\n",
    "            build_layers(20, 20),\n",
    "            build_layers(20, 20),\n",
    "            nn.Linear(20, 1)\n",
    "        )\n",
    "        \n",
    "        self.bias = nn.Parameter(torch.tensor([Diff_Eq.y0()]))\n",
    "        # self.bias = Diff_Eq.y0()\n",
    "        \n",
    "        return \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.fc(x)\n",
    "        \n",
    "        \n",
    "        out = out + self.bias \n",
    "        \n",
    "        return out\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback import print_tb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 6\n",
    "\n",
    "loss_list = {\n",
    "    \"mse\": [],\n",
    "    \"init\": [],\n",
    "    \"total\": []\n",
    "    \n",
    "}\n",
    "\n",
    "visualized_imgs = []\n",
    "\n",
    "val_x = torch.linspace(dataloader.dataset.x_from, dataloader.dataset.x_to, 1000).to(device).view(-1, 1)\n",
    "val_x.requires_grad = True\n",
    "val_y = model(val_x)\n",
    "\n",
    "visualized_imgs.append(plt.gcf())\n",
    "\n",
    "#　学習開始時点での解を描画\n",
    "plt.plot(val_x.cpu().detach().numpy(), val_y.cpu().detach().numpy(), label=\"pred\")\n",
    "plt.plot(val_x.cpu().detach().numpy(), Diff_Eq.y(val_x).cpu().detach().numpy(), label=\"true\")\n",
    "plt.legend() \n",
    "plt.title(f\"solution before training\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    print(f\"epoch: {epoch}\")\n",
    "    \n",
    "    loss_list[\"mse\"].append(0)\n",
    "    loss_list[\"init\"].append(0)\n",
    "    loss_list[\"total\"].append(0)\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    for x in tqdm(dataloader):\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x : torch.Tensor = x.to(device)\n",
    "        x.requires_grad = True\n",
    "        y_prime : torch.Tensor = Diff_Eq.y_prime(x, Diff_Eq.y(x))\n",
    "        \n",
    "        y_pred: torch.Tensor = model(x)\n",
    "        \n",
    "\n",
    "        y_prime_pred = torch.autograd.grad(y_pred.sum(), x, create_graph=True)[0]\n",
    "        \n",
    "        # print(y_prime_pred)\n",
    "        \n",
    "        loss_mse = F.mse_loss(y_prime_pred, y_prime)\n",
    "\n",
    "        \n",
    "        y0_pred  = model(torch.tensor([[Diff_Eq.x0]]).to(device))\n",
    "        y0_true = torch.tensor([[Diff_Eq.y0()]]).to(device)\n",
    "        loss_init = (y0_pred - y0_true) ** 2\n",
    "        \n",
    "        loss = loss_mse + loss_init * 0.01\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_list[\"mse\"][-1] += loss_mse.item()\n",
    "        loss_list[\"init\"][-1] += loss_init.item()\n",
    "        loss_list[\"total\"][-1] += loss.item()\n",
    "    \n",
    "    loss_list[\"mse\"][-1] /= len(dataloader)\n",
    "    loss_list[\"init\"][-1] /= len(dataloader)\n",
    "    loss_list[\"total\"][-1] /= len(dataloader)\n",
    "    \n",
    "    print(f\"loss_mse: {loss_list['mse'][-1]}\")\n",
    "    print(f\"loss_init: {loss_list['init'][-1]}\")\n",
    "    print(f\"loss_total: {loss_list['total'][-1]}\")\n",
    "    \n",
    "    val_x = torch.linspace(dataloader.dataset.x_from, dataloader.dataset.x_to, 1000).to(device).view(-1, 1)\n",
    "    val_x.requires_grad = True\n",
    "    val_y = model(val_x)\n",
    "    \n",
    "    visualized_imgs.append(plt.gcf())\n",
    "    \n",
    "    plt.plot(val_x.cpu().detach().numpy(), val_y.cpu().detach().numpy(), label=\"pred\")\n",
    "    plt.plot(val_x.cpu().detach().numpy(), Diff_Eq.y(val_x).cpu().detach().numpy(), label=\"true\")\n",
    "    plt.legend() \n",
    "    plt.title(f\"solution at iteration {epoch * len(dataloader)}\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "    # 微分値についても描画\n",
    "    val_y_prime = torch.autograd.grad(val_y.sum(), val_x, create_graph=True)[0]\n",
    "    plt.plot(val_x.cpu().detach().numpy(), val_y_prime.cpu().detach().numpy(), label=\"pred\")\n",
    "    plt.plot(val_x.cpu().detach().numpy(), Diff_Eq.y_prime(val_x, val_y).cpu().detach().numpy(), label=\"true\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"derivative of solution at epoch {epoch}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "val_x = torch.linspace(dataloader.dataset.x_from, dataloader.dataset.x_to, 1000).to(device).view(-1, 1)\n",
    "val_x.requires_grad = True\n",
    "val_y = model(val_x)\n",
    "\n",
    "plt.plot(val_x.cpu().detach().numpy(), val_y.cpu().detach().numpy(), label=\"pred\")\n",
    "plt.plot(val_x.cpu().detach().numpy(), Diff_Eq.y(val_x).cpu().detach().numpy(), label=\"true\")\n",
    "plt.legend() \n",
    "plt.title(f\"solution at iteration {epoch * len(dataloader)}\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 微分値についても描画\n",
    "val_y_prime = torch.autograd.grad(val_y.sum(), val_x, create_graph=True)[0]\n",
    "plt.plot(val_x.cpu().detach().numpy(), val_y_prime.cpu().detach().numpy(), label=\"pred\")\n",
    "plt.plot(val_x.cpu().detach().numpy(), Diff_Eq.y_prime(val_x, val_y).cpu().detach().numpy(), label=\"true\")\n",
    "plt.legend()\n",
    "plt.title(f\"derivative of solution at iteration {epoch * len(dataloader)}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アニメーションとしてgifに保存\n",
    "# 再生速度を設定する\n",
    "import imageio\n",
    "\n",
    "images = []\n",
    "for img in visualized_imgs:\n",
    "    img.savefig(\"tmp.png\")\n",
    "    images.append(imageio.imread(\"tmp.png\"))\n",
    "    \n",
    "imageio.mimsave('result1.gif', images, fps=1)\n",
    "    \n",
    "        \n",
    "import os\n",
    "os.remove(\"tmp.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初期値補正バイアスを活用した場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "model: Net = Net()\n",
    "\n",
    "\n",
    "model.bias = nn.Parameter(torch.tensor([0.0]))\n",
    "model.bias.requires_grad = False\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初期値補正バイアスを利用しなかった場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback import print_tb\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 12\n",
    "\n",
    "loss_list = {\n",
    "    \"mse\": [],\n",
    "    \"init\": [],\n",
    "    \"total\": []\n",
    "}\n",
    "\n",
    "visualized_imgs = []\n",
    "\n",
    "val_x = torch.linspace(dataloader.dataset.x_from, dataloader.dataset.x_to, 1000).to(device).view(-1, 1)\n",
    "val_x.requires_grad = True\n",
    "val_y = model(val_x)\n",
    "\n",
    "visualized_imgs.append(plt.gcf())\n",
    "\n",
    "#　学習開始時点での解を描画\n",
    "plt.plot(val_x.cpu().detach().numpy(), val_y.cpu().detach().numpy(), label=\"pred\")\n",
    "plt.plot(val_x.cpu().detach().numpy(), Diff_Eq.y(val_x).cpu().detach().numpy(), label=\"true\")\n",
    "plt.legend()\n",
    "\n",
    "plt.title(f\"solution before training\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    print(f\"epoch: {epoch}\")\n",
    "    \n",
    "    loss_list[\"mse\"].append(0)\n",
    "    loss_list[\"init\"].append(0)\n",
    "    loss_list[\"total\"].append(0)\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    \n",
    "    for x in tqdm(dataloader):\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        x : torch.Tensor = x.to(device)\n",
    "        x.requires_grad = True\n",
    "        y_prime : torch.Tensor = Diff_Eq.y_prime(x, Diff_Eq.y(x))\n",
    "        \n",
    "        y_pred: torch.Tensor = model(x)\n",
    "        \n",
    "\n",
    "        y_prime_pred = torch.autograd.grad(y_pred.sum(), x, create_graph=True)[0]\n",
    "        \n",
    "        # print(y_prime_pred)\n",
    "        \n",
    "        loss_mse = F.mse_loss(y_prime_pred, y_prime)\n",
    "\n",
    "        \n",
    "        y0_pred  = model(torch.tensor([[Diff_Eq.x0]]).to(device))\n",
    "        y0_true = torch.tensor([[Diff_Eq.y0()]]).to(device)\n",
    "        loss_init = (y0_pred - y0_true) ** 2\n",
    "        \n",
    "        loss = loss_mse + loss_init * 0.01\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_list[\"mse\"][-1] += loss_mse.item()\n",
    "        loss_list[\"init\"][-1] += loss_init.item()\n",
    "        loss_list[\"total\"][-1] += loss.item()\n",
    "    \n",
    "    loss_list[\"mse\"][-1] /= len(dataloader)\n",
    "    loss_list[\"init\"][-1] /= len(dataloader)\n",
    "    loss_list[\"total\"][-1] /= len(dataloader)\n",
    "    \n",
    "    print(f\"loss_mse: {loss_list['mse'][-1]}\")\n",
    "    print(f\"loss_init: {loss_list['init'][-1]}\")\n",
    "    print(f\"loss_total: {loss_list['total'][-1]}\")\n",
    "    \n",
    "    val_x = torch.linspace(dataloader.dataset.x_from, dataloader.dataset.x_to, 1000).to(device).view(-1, 1)\n",
    "    val_x.requires_grad = True\n",
    "    val_y = model(val_x)\n",
    "    \n",
    "    visualized_imgs.append(plt.gcf())\n",
    "    \n",
    "    plt.plot(val_x.cpu().detach().numpy(), val_y.cpu().detach().numpy(), label=\"pred\")\n",
    "    plt.plot(val_x.cpu().detach().numpy(), Diff_Eq.y(val_x).cpu().detach().numpy(), label=\"true\")\n",
    "    plt.legend() \n",
    "    plt.title(f\"solution at epoch {epoch}\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    # 微分値についても描画\n",
    "    val_y_prime = torch.autograd.grad(val_y.sum(), val_x, create_graph=True)[0]\n",
    "    plt.plot(val_x.cpu().detach().numpy(), val_y_prime.cpu().detach().numpy(), label=\"pred\")\n",
    "    plt.plot(val_x.cpu().detach().numpy(), Diff_Eq.y_prime(val_x, val_y).cpu().detach().numpy(), label=\"true\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"derivative of solution at iteration {epoch * len(dataloader)}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "val_x = torch.linspace(dataloader.dataset.x_from, dataloader.dataset.x_to, 1000).to(device).view(-1, 1)\n",
    "val_x.requires_grad = True\n",
    "val_y = model(val_x)\n",
    "\n",
    "plt.plot(val_x.cpu().detach().numpy(), val_y.cpu().detach().numpy(), label=\"pred\")\n",
    "plt.plot(val_x.cpu().detach().numpy(), Diff_Eq.y(val_x).cpu().detach().numpy(), label=\"true\")\n",
    "plt.legend() \n",
    "plt.title(f\"solution at iteration {epoch * len(dataloader)}\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 微分値についても描画\n",
    "val_y_prime = torch.autograd.grad(val_y.sum(), val_x, create_graph=True)[0]\n",
    "plt.plot(val_x.cpu().detach().numpy(), val_y_prime.cpu().detach().numpy(), label=\"pred\")\n",
    "plt.plot(val_x.cpu().detach().numpy(), Diff_Eq.y_prime(val_x, val_y).cpu().detach().numpy(), label=\"true\")\n",
    "plt.legend()\n",
    "plt.title(f\"derivative of solution at iteration {epoch * len(dataloader)}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アニメーションとしてgifに保存\n",
    "# 再生速度を設定する\n",
    "import imageio\n",
    "\n",
    "images = []\n",
    "for img in visualized_imgs:\n",
    "    img.savefig(\"tmp.png\")\n",
    "    images.append(imageio.imread(\"tmp.png\"))\n",
    "    \n",
    "imageio.mimsave('result2.gif', images, fps=1)\n",
    "    \n",
    "        \n",
    "import os\n",
    "os.remove(\"tmp.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
